<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Hao Zhou</title>

  <meta name="author" content="Hao Zhou">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:950px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p  class="name" style="text-align: center;">
                    <name>Hao Zhou</name>
                  </p>
                  <p>I am a senior software enginner at <a href="https://research.google">Google Research</a> where I
                    work on computer vision and machine learning.
                  </p>
                  <p>
                    <b>Bio:</b> I obtrained my PhD at Department of Computer Science, University of Maryland, College
                    Park supervied by Prof. <a href="https://www.cs.umd.edu/~djacobs/">David W. Jacobs</a> in 2019.
                    Before that, I received an M.Phil. from the University of Hong Kong under supervision of Dr. <a
                      href="http://i.cs.hku.hk/~kykwong/">Kenneth K.Y. Wong</a> in 2012, and a B.Eng in the University
                    of Science and Technology of China in 2010.
                  </p>
                  <p>
                    During my PhD studies, I was lucky to join Adobe Research,
                    NEC Labs America and National ICT (NICTA) Australia as a research intern.
                  </p>
                  <p>
                    Before joining Google Research, I worked as an applied scientist in <a
                      ref="https://aws.amazon.com/rekognition/">AWS Rekognition</a>.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:zhhoper@gmail.com">Email</a> &nbsp/&nbsp
                    <a href="data/HaoZhou-CV.pdf">CV</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=LSkAN30AAAAJ&hl=en">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/zhhoper/">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/HaoZhou.JPG"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/HaoZhou.JPG" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    Much of my current work is about image/video understanding. During my PhD stuides, my research is
                    mainly about understanding lighting from images.
                    Some selected papers are listed below. For a full list of papers, refer to my <a
                      href="https://scholar.google.com/citations?user=LSkAN30AAAAJ&hl=en">Google Scholar</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <!--VideoGLUE-->
              <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/videoglue.png' width="400" , style="horizontal-align:middle">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a
                    href="https://arxiv.org/pdf/2307.03166.pdf">
                    <papertitle>VideoGLUE: Video General Understanding Evaluation of Foundation Models.</papertitle>
                  </a>
                  <br>Liangzhe Yuan, Nitesh Bharadwaj Gundavarapu, Long Zhao, <strong>Hao Zhou</strong>, Yin Cui, Lu
                  Jiang, Xuan Yang, Menglin Jia, Tobias Weyand, Luke Friedman, Mikhail Sirotenko, Huisheng Wang, Florian
                  Schroff, Hartwig Adam, Ming-Hsuan Yang, Ting Liu and Boqing Gong.<br>
                  <em>Arxiv</em>, 2023.
                  </br>
                  <a
                    href="https://arxiv.org/pdf/2307.03166.pdf">Paper</a>
                </td>
              </tr>
            </tbody>
            <!--RegNas-->
            <tbody>
              <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/regnas.png' width="300" , style="vertical-align:middle">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/pdf/2209.13740.pdf">
                    <papertitle>Towards Regression-Free Neural Networks for Diverse Compute Platforms.</papertitle>
                  </a>
                  <br>Rahul Duggal, <strong>Hao Zhou</strong>, Shuo Yang, Jun Fang, Yuanjun Xiong and Wei Xia.<br>
                  <em>ECCV</em>, 2022.
                  </br>
                  <!-- <br>
              <em>ECCV</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation, Outstanding Paper
                  Award)</strong></font>
              <br> -->
                  <a href="https://arxiv.org/pdf/2209.13740.pdf">Paper</a>
                </td>
              </tr>
            </tbody>
            <!--PSS-->
            <tbody>
              <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/pss.png' width="400" , style="vertical-align:middle">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a
                    href="https://assets.amazon.science/16/59/b75cf9544b1dbf76e255d3297d64/pss-progressive-sample-selection-for-open-world-visual-representation-learning.pdf">
                    <papertitle>PSS: Progressive Sample Selection for Open-World Visual Representation Learning
                    </papertitle>
                  </a>
                  <br>Tianyue Cao, Yongxin Wang, Yifan Xing, Tianjun Xiao, Tong He, Zheng Zhang, <strong>Hao
                    Zhou</strong>, and Joseph Tighe.<br>
                  <em>ECCV</em>, 2022.
                  </br>
                  <a
                    href="https://assets.amazon.science/16/59/b75cf9544b1dbf76e255d3297d64/pss-progressive-sample-selection-for-open-world-visual-representation-learning.pdf">Paper</a>
                  /
                  <a href="https://github.com/dmlc/dgl/tree/master/examples/pytorch/hilander/PSS">Code</a>
                </td>
              </tr>
            </tbody>
          </table>
          <table>
            <!--CMPNAS-->
            <tbody>
              <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/cmpnas.png' width="400" , style="vertical-align:middle">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a
                    href="https://openaccess.thecvf.com/content/CVPR2021/papers/Duggal_Compatibility-Aware_Heterogeneous_Visual_Search_CVPR_2021_paper.pdf">
                    <papertitle>Compatibility-aware Heterogeneous Visual Search.</papertitle>
                  </a>
                  <br>Rahul Duggal, <strong>Hao Zhou</strong>, Shuo Yang, Yuanjun Xiong, Wei Xia, Zhuowen Tu, Stefano
                  Soatto.<br>
                  <em>CVPR</em>, 2021.
                  </br>
                  <a
                    href="https://openaccess.thecvf.com/content/CVPR2021/papers/Duggal_Compatibility-Aware_Heterogeneous_Visual_Search_CVPR_2021_paper.pdf">Paper</a>
                  <p></p>
                  <p><strong>Mentioned by the VP of AWS AI in <a
                        href="https://www.amazon.science/latest-news/graceful-ai">Graceful AI</a></strong></p>
                </td>
              </tr>
            </tbody>
          </table>
          <table>
            <!--sharegan-->
            <tbody>
              <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/sharegan.png' width="400" , style="vertical-align:middle">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a
                    href="https://openaccess.thecvf.com/content_CVPR_2020/papers/PNVR_SharinGAN_Combining_Synthetic_and_Real_Data_for_Unsupervised_Geometry_Estimation_CVPR_2020_paper.pdf">
                    <papertitle>SharinGAN: Combining Synthetic and Real Data for Unsupervised Geometry Estimation.
                    </papertitle>
                  </a>
                  <br>Koutilya PNVR, <strong>Hao Zhou</strong>, David Jacobs.<br>
                  <em>CVPR</em>, 2020.
                  </br>
                  <a
                    href="https://openaccess.thecvf.com/content_CVPR_2020/papers/PNVR_SharinGAN_Combining_Synthetic_and_Real_Data_for_Unsupervised_Geometry_Estimation_CVPR_2020_paper.pdf">Paper</a>
                  /
                  <a href="https://github.com/koutilya-pnvr/SharinGAN">Code</a>
                </td>
              </tr>
            </tbody>
          </table>
          <table>
            <!--DPR-->
            <tbody>
              <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/obama.gif' width="400" , style="vertical-align:middle">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="old_version/dpr.html">
                    <papertitle>Deep Single-Image Portrait Relighting.</papertitle>
                  </a>
                  <br><strong>Hao Zhou</strong>, Sunil Hadap, Kalyan Sunkavalli and David W. Jacobs<br>
                  <em>ICCV</em>, 2019.
                  </br>
                  <a
                    href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhou_Deep_Single-Image_Portrait_Relighting_ICCV_2019_paper.pdf">Paper</a>
                  /
                  <a href="https://github.com/koutilya-pnvr/SharinGAN">Code</a>
                  /
                  <a href="old_version/dpr.html">Project</a>
                  <p></p>
                  <p><strong>Covered by <a href="https://www.youtube.com/watch?v=Ks7wDYsN4yM">Two Minutes
                        Paper</a></strong></p>
                </td>
              </tr>
            </tbody>
          </table>
          <table>
            <!--GloSH-->
            <tbody>
              <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/glosh.png' width="400" , style="vertical-align:middle">
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a
                    href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhou_GLoSH_Global-Local_Spherical_Harmonics_for_Intrinsic_Image_Decomposition_ICCV_2019_paper.pdf">
                    <papertitle>GLoSH: Global-Local Spherical Harmonics for Intrinsic Image Decomposition.</papertitle>
                  </a>
                  <br><strong>Hao Zhou</strong>, Xiang Yu and David W. Jacobs<br>
                  <em>ICCV</em>, 2019. &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                  </br>
                  <a
                    href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhou_GLoSH_Global-Local_Spherical_Harmonics_for_Intrinsic_Image_Decomposition_ICCV_2019_paper.pdf">Paper</a>
                </td>
              </tr>
            </tbody>
            <table>
              <!--LDAN-->
              <tbody>
                <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src='images/LDAN.png' width="400" , style="vertical-align:middle">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a
                      href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhou_Label_Denoising_Adversarial_CVPR_2018_paper.pdf">
                      <papertitle>Label Denoising Adversarial Network (LDAN) for Inverse Lighting of Faces.</papertitle>
                    </a>
                    <br><strong>Hao Zhou</strong>, Jin Sun, Yaser Yacoob and David W. Jacobs<br>
                    <em>CVPR</em>, 2018. &nbsp <font color="red"><strong>(Spotlight)</strong></font>
                    </br>
                    <a
                      href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhou_Label_Denoising_Adversarial_CVPR_2018_paper.pdf">Paper</a>
                  </td>
                </tr>
              </tbody>
            </table>
            <table>
              <!--Lowrank-->
              <tbody>
                <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src='images/lowrank.png' width="400" , style="vertical-align:middle">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a
                      href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Zhou_Label_Denoising_Adversarial_CVPR_2018_paper.pdf">
                      <papertitle>Solving Uncalibrated Photometric Stereo Using Fewer Images by Jointly Optimizing
                        Low-rank Matrix Completion and Integrability.</papertitle>
                    </a>
                    <br>Soumyadip Sengupta, <strong>Hao Zhou</strong>, Walter Forkel, Ronen Basri, Tom Goldstein, David
                    W Jacobs.<br>
                    <em>JMIV</em>, 2017.
                    </br>
                    <a href="https://arxiv.org/pdf/1702.00506.pdf">Paper</a>
                  </td>
                </tr>
              </tbody>
            </table>
            <table>
              <!--Less is More-->
              <tbody>
                <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src='images/Less_is_more.png' width="400" , style="vertical-align:middle">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="old_version/paper/zhou_ECCV2016.pdf">
                      <papertitle>Less is More: Towards Compact CNNs.</papertitle>
                    </a>
                    <br><strong>Hao Zhou</strong>, Jose M. Alvarez and Fatih Porikli.<br>
                    <em>ECCV</em>, 2016. &nbsp <font color="red"><strong>(Spotlight)</strong></font>
                    </br>
                    <a href="https://arxiv.org/pdf/1702.00506.pdf">Paper</a>
                  </td>
                </tr>
              </tbody>
            </table>
            <table>
              <!--DayNightMatching-->
              <tbody>
                <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src='images/DayNigh.png' width="400" , style="vertical-align:middle">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="old_version/paper/zhou_ECCVW_2016.pdf">
                      <papertitle>Evaluating Local Features for Day-Night Matching.</papertitle>
                    </a>
                    <br><strong>Hao Zhou</strong>, Torsten Sattler and Fatih Porikli.<br>
                    <em>ECCV Workshop on Local Features: State of the Art, Open Problems and Performance Analysis</em>,
                    2016.
                    </br>
                    <a href="old_version/paper/zhou_ECCVW_2016.pdf">Paper</a>
                  </td>
                </tr>
              </tbody>
            </table>
            <table>
              <!--MRF-->
              <tbody>
                <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()">
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <img src='images/MRF.png' width="400" , style="vertical-align:middle">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="old_version/paper/zhou_cvpr12.pdf">
                      <papertitle>Markov Weight Fields for Face Sketch Synthesis.</papertitle>
                    </a>
                    <br><strong>Hao Zhou</strong>, Zhanghui Kuang and Kwan-Yee K. Wong.<br>
                    <em>CVPR</em>, 2012.
                    </br>
                    <a href="old_version/paper/zhou_cvpr12.pdf">Paper</a>
                  </td>
                </tr>
              </tbody>
            </table>
            <table
              style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:20px">
                    <br>
                    <p>
                      The portrait is drawn by <a href="https://research.adobe.com/person/daichi-ito/">Daichi Ito</a>
                      when I interned in Adobe.
                    </p>
                    <p>
                      This website is designed according to the website of <a href="https://jonbarron.info">Jon Barron</a>.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>
        </td>
      </tr>
  </table>
</body>
</html>
